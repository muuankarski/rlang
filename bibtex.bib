
@misc{smith_r_2010,
	title = {R is Hot - How Did a Statistical Programming Language Invented in New Zealand Become a Global Sensation?},
	publisher = {Revolution Analytics},
	author = {Smith, David},
	year = {2010},
	file = {R-is-Hot.pdf:/home/aurelius/.mozilla/firefox/0c1z5fdv.default/zotero/storage/U7HBBWRE/R-is-Hot.pdf:application/pdf}
},

@book{chang2012r,
  title={R graphics cookbook},
  author={Chang, Winston},
  year={2012},
  publisher={O'Reilly}
},

@book{jockers2013macroanalysis,
  title={Macroanalysis: Digital Methods and Literary History},
  author={Jockers, Matthew L},
  year={2013},
  publisher={University of Illinois Press}
},


@book{wickham_r_2017,
	edition = {1 edition},
	title = {R for {Data} {Science}: {Import}, {Tidy}, {Transform}, {Visualize}, and {Model} {Data}},
	isbn = {978-1-4919-1039-9},
	shorttitle = {R for {Data} {Science}},
	abstract = {Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible.Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. You’ll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what you’ve learned along the way.You’ll learn how to:Wrangle—transform your datasets into a form convenient for analysisProgram—learn powerful R tools for solving data problems with greater clarity and easeExplore—examine your data, generate hypotheses, and quickly test themModel—provide a low-dimensional summary that captures true "signals" in your datasetCommunicate—learn R Markdown for integrating prose, code, and results},
	language = {English},
	publisher = {O'Reilly Media},
	author = {Wickham, Hadley and Grolemund, Garrett},
	month = jan,
	year = {2017}
}


@article{wilson_good_2016,
	title = {Good {Enough} {Practices} in {Scientific} {Computing}},
	url = {http://arxiv.org/abs/1609.00037},
	abstract = {We present a set of computing tools and techniques that every researcher can and should adopt. These recommendations synthesize inspiration from our own work, from the experiences of the thousands of people who have taken part in Software Carpentry and Data Carpentry workshops over the past six years, and from a variety of other guides. Unlike some other guides, our recommendations are aimed specifically at people who are new to research computing.},
	urldate = {2016-09-07},
	journal = {arXiv:1609.00037 [cs]},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = aug,
	year = {2016},
	note = {arXiv: 1609.00037},
	keywords = {Computer Science - Software Engineering},
	annote = {Comment: 19 pages, 1 figure},
	file = {arXiv\:1609.00037 PDF:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/5C4HQVTV/Wilson ym. - 2016 - Good Enough Practices in Scientific Computing.pdf:application/pdf;arXiv.org Snapshot:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/JS3QZ492/1609.html:text/html}
}

@book{gelman_bayesian_2013,
	title = {Bayesian Data Analysis, Third Edition},
	isbn = {9781439840955},
	abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
	language = {en},
	publisher = {{CRC} Press},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	month = nov,
	year = {2013},
	keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General, Psychology / Research \& Methodology}
},



@book{xie_dynamic_2014,
	title = {Dynamic documents with R and knitr},
	isbn = {9781482203530  1482203537},
	abstract = {{"Suitable} for both beginners and advanced users, this book shows you how to write reports in simple languages such as Markdown. The reports range from homework, projects, exams, books, blogs, and web pages to any documents related to statistical graphics, computing, and data analysis. While familiarity with {LaTeX} and {HTML} is helpful, the book requires no prior experience with advanced programs or languages. For beginners, the text provides enough features to get started on basic applications. For power users, the last several chapters enable an understanding of the extensibility of the knitr package."-- {"Preface} We import a dataset into a statistical software package, run a procedure to get all results, then copy and paste selected pieces into a typesetting program, add a few descriptions and finish a report. This is a common practice of writing statistical reports. There are obvious dangers and disadvantages in this process: 1. it is error-prone due to too much manual work; 2. it requires lots of human efforts to do tedious jobs such as copying results across documents; 3. the workflow is barely recordable especially when it involves {GUI} (Graphical User Interface) operations, therefore it is difficult to reproduce; 4. a tiny change of the data source in the future will require the author(s) to go through the same procedure again, which can take nearly the same amount of time and effort; 5. the analysis and writing are separate, so close attention has to be paid to the synchronization of the two parts; In fact, a report can be generated dynamically from program code. Just like a software package has its source code, a dynamic document is the source code of a report. It is a combination of computer code and the corresponding narratives. When we compile the dynamic document, the program code in it is executed and replaced with the output; we get a final report by mixing the code output with the narratives. Because we only manage the source code, we are free of all the possible problems above. For example, we can change a single parameter in the source code, and get a different report on the fly."--},
	language = {English},
	publisher = {{CRC} Press},
	author = {Xie, Yihui},
	year = {2014}
},


@book{snijders_multilevel_2011,
	edition = {Second Edition},
	title = {Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling},
	isbn = {{184920201X}},
	shorttitle = {Multilevel Analysis},
	publisher = {Sage Publications Ltd},
	author = {Snijders, Tom A. B. and Bosker, Roel},
	month = dec,
	year = {2011}
},



@book{field_discovering_2012,
	title = {Discovering Statistics Using R},
	isbn = {9781446258460},
	abstract = {Lecturers, click here to request an e-inspection copy of this text           Watch Andy Field's introductory video to Discovering Statistics Using R       Keeping the uniquely humorous and self-deprecating style that has made students across the world fall in love with Andy Field's books, Discovering Statistics Using R takes students on a journey of statistical discovery using R, a free, flexible and dynamically changing software tool for data analysis that is becoming increasingly popular across the social and behavioural sciences throughout the world.   The journey begins by explaining basic statistical and research concepts before a guided tour of the R software environment. Next you discover the importance of exploring and graphing data, before moving onto statistical tests that are the foundations of the rest of the book (for example correlation and regression). You will then stride confidently into intermediate level analyses such as {ANOVA}, before ending your journey with advanced techniques such as {MANOVA} and multilevel models. Although there is enough theory to help you gain the necessary conceptual understanding of what you're doing, the emphasis is on applying what you learn to playful and real-world examples that should make the experience more fun than you might expect.   Like its sister textbooks, Discovering Statistics Using R is written in an irreverent style and follows the same ground-breaking structure and pedagogical approach. The core material is augmented by a cast of characters to help the reader on their way, together with hundreds of examples, self-assessment tests to consolidate knowledge, and additional website material for those wanting to learn more at: Instructor Site.   Given this book's accessibility, fun spirit, and use of bizarre real-world research it should be essential for anyone wanting to learn about statistics using the freely-available R software.},
	language = {en},
	publisher = {{SAGE}},
	author = {Field, Andy and Miles, Jeremy and Field, Zoë},
	month = mar,
	year = {2012},
	keywords = {Reference / Research}
},


@book{kabacoff_r_2013,
	title = {R in Action: Data Analysis and Graphics With R},
	isbn = {9781617291388},
	shorttitle = {R in Action},
	abstract = {R is a powerful language for statistical computing and graphics that can handle virtually any data-crunching task. It runs on all important platforms and provides thousands of useful specialized modules and utilities. This makes R a great way to get meaningful information from mountains of raw {data.R} in Action, Second Edition is a language tutorial focused on practical problems. Written by a research methodologist, it takes a direct and modular approach to quickly give readers the information they need to produce useful results. Focusing on realistic data analyses and a comprehensive integration of graphics, it follows the steps that real data analysts use to acquire their data, get it into shape, analyze it, and produce meaningful results that they can provide to clients. Purchase of the print book comes with an offer of a free {PDF} {eBook} from Manning. Also available is all code from the book.},
	language = {en},
	publisher = {{MANNING} {PUBN}},
	author = {Kabacoff, Robert},
	month = nov,
	year = {2013},
	keywords = {Computers / Databases / Data Mining, Computers / Databases / General, Computers / Data Processing, Computers / Mathematical \& Statistical Software}
},

@book{manovich_software_2013,
	address = {New York},
	title = {Software Takes Command},
	isbn = {9781623567453 1623567459},
	language = {English},
	publisher = {{CONTINUUM} {PUBLISHING} {CORPORATION}},
	author = {Manovich, Lev},
	year = {2013}
},


@book{lumley_complex_2011,
	title = {Complex Surveys: A Guide to Analysis Using R},
	isbn = {9781118210932},
	shorttitle = {Complex Surveys},
	abstract = {A complete guide to carrying out complex survey analysis using {RAs} survey analysis continues to serve as a core component of sociological research, researchers are increasingly relying upon data gathered from complex surveys to carry out traditional analyses. Complex Surveys is a practical guide to the analysis of this kind of data using R, the freely available and downloadable statistical programming language. As creator of the specific survey package for R, the author provides the ultimate presentation of how to successfully use the software for analyzing data from complex surveys while also utilizing the most current data from health and social sciences studies to demonstrate the application of survey research methods in these {fields.The} book begins with coverage of basic tools and topics within survey analysis such as simple and stratified sampling, cluster sampling, linear regression, and categorical data regression. Subsequent chapters delve into more technical aspects of complex survey analysis, including post-stratification, two-phase sampling, missing data, and causal inference. Throughout the book, an emphasis is placed on graphics, regression modeling, and two-phase designs. In addition, the author supplies a unique discussion of epidemiological two-phase designs as well as probability-weighting for causal inference. All of the book's examples and figures are generated using R, and a related Web site provides the R code that allows readers to reproduce the presented content. Each chapter concludes with exercises that vary in level of complexity, and detailed appendices outline additional mathematical and computational descriptions to assist readers with comparing results from various software {systems.Complex} Surveys is an excellent book for courses on sampling and complex surveys at the upper-undergraduate and graduate levels. It is also a practical reference guide for applied statisticians and practitioners in the social and health sciences who use statistics in their everyday work.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Lumley, Thomas},
	month = sep,
	year = {2011},
	keywords = {Mathematics / Probability \& Statistics / General}
},


@article {king2014,
	title = {Restructuring the Social Sciences: Reflections from Harvard{\textquoteright}s Institute for Quantitative Social Science},
	journal = {PS: Political Science and Politics},
	volume = {47},
	year = {2014},
	pages = {165-172},
	abstract = {The social sciences are undergoing a dramatic transformation from studying problems to solving them; from making do with a small number of sparse data sets to analyzing increasing quantities of diverse, highly informative data; from isolated scholars toiling away on their own to larger scale, collaborative, interdisciplinary, lab-style research teams; and from a purely academic pursuit to having a major impact on the world. To facilitate these important developments, universities, funding agencies, and governments need to shore up and adapt the infrastructure that supports social science research. We discuss some of these developments here, as well as a new type of organization we created at Harvard to help encourage them -- the Institute for Quantitative Social Science. \&nbsp;An increasing number of universities are beginning efforts to respond with similar institutions. This paper provides some suggestions for how individual universities might respond and how we might work together to advance social science more generally.
<p>},
	url = {http://journals.cambridge.org/repo_A9100Nlq},
	author = {Gary King}
},

@book{jockers_text_2014,
	series = {Quantitative Methods in the Humanities and Social Sciences},
	title = {Text Analysis with R for Students of Literature},
    year = {forthcoming},
	publisher = {Springer},
	author = {Jockers, Matthew L.},
	file = {Jockers - Text Analysis with R for Students of Literature.pdf:/home/aurelius/.mozilla/firefox/zgntm85n.default/zotero/storage/ADKNC2IP/Jockers - Text Analysis with R for Students of Literature.pdf:application/pdf}
},

@misc{r-bloggers,
	title = {R-bloggers},
	url = {http://www.r-bloggers.com},
	abstract = {R news and tutorials contributed by (452) R bloggers},
	urldate = {2014-01-27},
	journal = {R-bloggers},
	keywords = {Big Data, blog, bloggers, blogging, {CRAN}, data science, ggplot2, git, hadoop, knitr, latex, lattice, open access, par, R, R blog, R forum, R help, R language, R list, R news, R programming, S, sas, Splus, spss, statistical programming, statistics, sweave},
	file = {Snapshot:/home/aurelius/.mozilla/firefox/zgntm85n.default/zotero/storage/HAT8F3B8/www.r-bloggers.com.html:text/html}
}

@article{lohr_literary_2013,
	chapter = {Technology},
	title = {Literary History, Seen Through Big Data’s Lens},
	issn = {0362-4331},
	url = {http://www.nytimes.com/2013/01/27/technology/literary-history-seen-through-big-datas-lens.html},
	urldate = {2013-01-28},
	journal = {The New York Times},
	author = {Lohr, Steve},
	month = jan,
	year = {2013},
	keywords = {Books and Literature, Computers and the Internet, Google Book Search, Jockers, Matthew L., Macroanalysis: Digital Methods and Literary History (Book), Research, Writing and Writers},
	file = {New York Times Snapshot:/home/aurelius/.mozilla/firefox/5mixbles.default/zotero/storage/9TR2T2ZG/literary-history-seen-through-big-datas-lens.html:text/html}
},

@book{jockers_macroanalysis_2013,
	edition = {1st Edition},
	title = {Macroanalysis: Digital Methods and Literary History},
	isbn = {0252079078},
	shorttitle = {Macroanalysis},
	publisher = {University of Illinois Press},
	author = {Jockers, Matthew L.},
	month = jun,
	year = {2013}
},


@article{king_how_2012,
	title = {How Censorship in China Allows Government Criticism but Silences Collective Expression},
	journal = {American Political Science Review},
	author = {King, Gary and Pan, Jennifer and Roberts, Molly},
	year = {2012},
	file = {How Censorship in China Allows Government Criticism but Silences Collective Expression | Gary King:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/DPH7KK3Z/how-censorship-china-allows-government-criticism-silences-collective-expression.html:text/html}
},


@misc{louhos_2013,
	title = {Louhos: Lähdekoodia avointen suomalaisten datavirtojen seulontaan},
	shorttitle = {Louhos},
	author = {Lahti, Leo and Lehtomäki, Joona and Parkkinen, Juuso},
	year = {2013},
	url = {http://louhos.github.com/}
},


@article{hetherington_how_2012,
	title = {How Trust Matters: The Changing Political Relevance of Political Trust},
	volume = {56},
	copyright = {© 2011, Midwest Political Science Association},
	issn = {1540-5907},
	shorttitle = {How Trust Matters},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1540-5907.2011.00548.x/abstract},
	doi = {10.1111/j.1540-5907.2011.00548.x},
	abstract = {Americans most often think about government in terms of its ability to grapple with issues of redistribution and race. However, the September 11 terrorist attacks led to a massive increase in media attention to foreign affairs, which caused people to think about the government in terms of defense and foreign policy. We demonstrate that such changes in issue salience alter the policy preferences that political trust shapes. Specifically, we show that trust did not affect attitudes about the race-targeted programs in 2004 as it usually does, but instead affected a range of foreign policy and national defense preferences. By merging survey data gathered from 1980 through 2004 with data from media content analyses, we show that, more generally, trust's effects on defense and racial policy preferences, respectively, increase as the media focus more attention in these areas and decrease when that attention ebbs.},
	language = {en},
	number = {2},
	urldate = {2013-01-29},
	journal = {American Journal of Political Science},
	author = {Hetherington, Marc J. and Husser, Jason A.},
	year = {2012},
	pages = {312–325},
	file = {Full Text PDF:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/2TCVKEIW/Hetherington ja Husser - 2012 - How Trust Matters The Changing Political Relevanc.pdf:application/pdf;Snapshot:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/DTWM7ZVI/full.html:text/html}
},


@article{lipsky_racial_2012,
	title = {Racial and Ethnic Disparities in Police-Reported Intimate Partner Violence Perpetration A Mixed Methods Approach},
	volume = {27},
	issn = {0886-2605, 1552-6518},
	url = {http://jiv.sagepub.com/content/27/11/2144},
	doi = {10.1177/0886260511432152},
	abstract = {The objectives of this study were to examine racial and ethnic disparities in perpetrator and incident characteristics and discrepancies between police charges and reported perpetrator behaviors in police-reported intimate partner violence ({IPV).} This cross-sectional study used standardized police data and victim narratives of {IPV} incidents reported to the police in Dallas, Texas in 2004. The sample included non-Hispanic White, non-Hispanic Black, and Hispanic male perpetrators who were residents of Dallas (N = 4470). Offense charges were prioritized in descending order: sexual assault, aggravated assault, simple assault, kidnapping, robbery, and intimidation. Textual data from the victim narratives were coded, based on the revised Conflict Tactics Scales ({CTS)}, and categorized in descending order of priority: sexual (severe, minor), physical (severe, minor), and psychological (severe, minor) assault. Perpetrators were more likely to be Black and Hispanic. Perpetrator and incident characteristics varied significantly by race/ethnicity, particularly age, age difference between partners, marital status, injury, and interracial relationships. Qualitative data revealed that greater proportions of Black and Hispanic men perpetrated severe physical, but not sexual violence, compared with White men. The greatest disparity between {CTS} categories and police charges occurred among those cases identified by the {CTS} as severe physical {IPV;} 84\% were charged with simple assault. Significant differences by race/ethnicity were found only for simple assault charges, which were coded as severe physical as opposed to minor physical {IPV} more often among Black (69\% and 31\%) compared with White (62\% and 38\%) men. The disparities revealed in this study highlight the need to enhance primary and secondary prevention efforts within Black and Hispanic communities and to increase linkages between police, community, and public health organizations.},
	language = {en},
	number = {11},
	urldate = {2013-01-29},
	journal = {Journal of Interpersonal Violence},
	author = {Lipsky, Sherry and Cristofalo, Meg and Reed, Sarah and Caetano, Raul and Roy-Byrne, Peter},
	month = jul,
	year = {2012},
	keywords = {criminology, legal intervention, violent offenders},
	pages = {2144--2162},
	file = {Full Text PDF:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/2NZCHPVJ/Lipsky et al. - 2012 - Racial and Ethnic Disparities in Police-Reported I.pdf:application/pdf;Snapshot:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/KRWB9EG7/2144.html:text/html}
},


@article{peng_reproducible_2011,
	title = {Reproducible Research in Computational Science},
	volume = {334},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/content/334/6060/1226},
	doi = {10.1126/science.1213847},
	abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
	language = {en},
	number = {6060},
	urldate = {2013-01-29},
	journal = {Science},
	author = {Peng, Roger D.},
	month = dec,
	year = {2011},
	pages = {1226--1227},
	file = {Full Text PDF:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/6K8FT8M6/Peng - 2011 - Reproducible Research in Computational Science.pdf:application/pdf;Snapshot:/home/aurelius/.mozilla/firefox/mwad0hks.default/zotero/storage/W7NIRNHQ/1226.html:text/html}
},


@misc{wiki_avoin_2013,
	title = {Avoin lähdekoodi},
	author = {Wikipedia},
	copyright = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://fi.wikipedia.org/w/index.php?title=Avoin_l%C3%A4hdekoodi&oldid=13074631},
	abstract = {Avoin lähdekoodi (engl. open source [əʊpən sɔːs]) tarkoittaa tietokoneohjelmien tuottamis- ja kehitysmenetelmiä, jotka tarjoavat käyttäjälle mahdollisuuden tutustua ohjelman lähdekoodiin ja muokata sitä omien tarpeidensa mukaisesti. Avoimen lähdekoodin periaatteisiin kuuluu myös vapaus käyttää ohjelmaa mihin tahansa tarkoitukseen ja kopioida ja levittää sekä alkuperäistä että muokattua versiota.},
	language = {fi},
	urldate = {2013-09-27},
	journal = {Wikipedia},
	month = aug,
	year = {2013},
	note = {Page Version {ID:} 13074631},
	file = {Snapshot:/home/aurelius/.mozilla/firefox/zgntm85n.default/zotero/storage/XETJVE33/index.html:text/html}
},

@article{simpura_nakymattomien_2012,
	title = {Näkymättömien sankarien tiede: tietovarannot kansallisaarteena},
	url = {http://www.saunalahti.fi/~nl03449/tiedepolitiikka_lehti/tp4_12.htm},
	number = {4},
	journal = {Tiedepolitiikka},
	author = {Simpura, Jussi},
	year = {2012}
},


@book{venables_introduction_2013,
	title = {An introduction to R},
	url = {http://www.math.vu.nl/sto/onderwijs/statlearn/R-Binder.pdf},
	urldate = {2013-05-28},
	publisher = {Network Theory},
	author = {Venables, William N. and Smith, David M. and Team, R. Development Core},
	year = {2013},
	file = {R-intro.pdf:/home/aurelius/.mozilla/firefox/zgntm85n.default/zotero/storage/3FCN54WC/R-intro.pdf:application/pdf}
}


